{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image_path, input_size=(300, 300), mean=(0.485, 0.456, 0.406, 0.0), std=(0.229, 0.224, 0.225, 1.0)):\n",
    "    # Load the image\n",
    "    image = Image.open(image_path).convert('RGBA')\n",
    "    \n",
    "    # Define the transformation\n",
    "    transform = create_transform(\n",
    "        input_size=input_size,\n",
    "        is_training=False,\n",
    "        use_prefetcher=False,\n",
    "        no_aug=False,\n",
    "        interpolation='bilinear',\n",
    "        mean=mean,\n",
    "        std=std,\n",
    "        crop_pct=None,\n",
    "        tf_preprocessing=False,\n",
    "    )\n",
    "    \n",
    "    tensor_image = transform(image).unsqueeze(0) \n",
    "\n",
    "    tensor_image = tensor_image.cuda() if torch.cuda.is_available() else tensor_image\n",
    "    \n",
    "    return tensor_image\n",
    "\n",
    "preprocessed_image = preprocess_image('test2.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 300, 300])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' for 4 tiles \\ndef cut_into_tiles_tensor(image_tensor, num_tiles=9):\\n\\n    if num_tiles != 4:\\n        raise ValueError(\"This function currently supports only 4 tiles.\")\\n    \\n    _, C, H, W = image_tensor.shape  \\n    tile_height, tile_width = H // 3, W // 3\\n    \\n    tiles = {\\n        \\'tl\\': image_tensor[:, :, :tile_height, :tile_width],\\n        \\'tr\\': image_tensor[:, :, :tile_height, tile_width:],\\n        \\'bl\\': image_tensor[:, :, tile_height:, :tile_width],\\n        \\'br\\': image_tensor[:, :, tile_height:, tile_width:]\\n    }\\n    \\n    return tiles\\n\\ntiles = cut_into_tiles_tensor(preprocessed_image, 4)\\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' for 4 tiles \n",
    "def cut_into_tiles_tensor(image_tensor, num_tiles=9):\n",
    "\n",
    "    if num_tiles != 4:\n",
    "        raise ValueError(\"This function currently supports only 4 tiles.\")\n",
    "    \n",
    "    _, C, H, W = image_tensor.shape  \n",
    "    tile_height, tile_width = H // 3, W // 3\n",
    "    \n",
    "    tiles = {\n",
    "        'tl': image_tensor[:, :, :tile_height, :tile_width],\n",
    "        'tr': image_tensor[:, :, :tile_height, tile_width:],\n",
    "        'bl': image_tensor[:, :, tile_height:, :tile_width],\n",
    "        'br': image_tensor[:, :, tile_height:, tile_width:]\n",
    "    }\n",
    "    \n",
    "    return tiles\n",
    "\n",
    "tiles = cut_into_tiles_tensor(preprocessed_image, 4)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_into_tiles_tensor(image_tensor, num_tiles=9):\n",
    "    if num_tiles != 9:\n",
    "        raise ValueError(\"This function currently supports only 9 tiles.\")\n",
    "    \n",
    "    _, C, H, W = image_tensor.shape\n",
    "    # Ensure the image dimensions are divisible by 3\n",
    "    if H % 3 != 0 or W % 3 != 0:\n",
    "        raise ValueError(\"Image dimensions must be divisible by 3.\")\n",
    "    \n",
    "    tile_height, tile_width = H // 3, W // 3\n",
    "    \n",
    "    tiles = {\n",
    "        'tl': image_tensor[:, :, :tile_height, :tile_width],  # Top left\n",
    "        'tc': image_tensor[:, :, :tile_height, tile_width:2*tile_width],  # Top center\n",
    "        'tr': image_tensor[:, :, :tile_height, 2*tile_width:],  # Top right\n",
    "        'ml': image_tensor[:, :, tile_height:2*tile_height, :tile_width],  # Middle left\n",
    "        'mc': image_tensor[:, :, tile_height:2*tile_height, tile_width:2*tile_width],  # Middle center\n",
    "        'mr': image_tensor[:, :, tile_height:2*tile_height, 2*tile_width:],  # Middle right\n",
    "        'bl': image_tensor[:, :, 2*tile_height:, :tile_width],  # Bottom left\n",
    "        'bc': image_tensor[:, :, 2*tile_height:, tile_width:2*tile_width],  # Bottom center\n",
    "        'br': image_tensor[:, :, 2*tile_height:, 2*tile_width:]  # Bottom right\n",
    "    }\n",
    "    \n",
    "    return tiles\n",
    "\n",
    "tiles = cut_into_tiles_tensor(preprocessed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_permuted_images_tensor(tiles, num_permutations):\n",
    "    # Assuming tiles is a dictionary of tensors and we have a square number of them\n",
    "    num_tiles = len(tiles)\n",
    "    n = int(math.sqrt(num_tiles))  # n x n grid\n",
    "    if n ** 2 != num_tiles:\n",
    "        raise ValueError(\"Number of tiles must be a perfect square.\")\n",
    "\n",
    "    tile_positions = list(tiles.keys())\n",
    "    permuted_images = []\n",
    "\n",
    "    for _ in range(num_permutations):\n",
    "        random.shuffle(tile_positions)\n",
    "        rows = []\n",
    "\n",
    "        for i in range(0, num_tiles, n):\n",
    "            # Concatenate tiles along width to form one row\n",
    "            row = torch.cat([tiles[pos] for pos in tile_positions[i:i+n]], dim=3)\n",
    "            rows.append(row)\n",
    "\n",
    "        # Concatenate all rows along height to form the new image\n",
    "        new_img_tensor = torch.cat(rows, dim=2)\n",
    "        permuted_images.append(new_img_tensor)\n",
    "\n",
    "    return torch.stack(permuted_images)\n",
    "\n",
    "permuted_images_tensors = create_permuted_images_tensor(tiles, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using relative_pos\n",
      "Grapher(\n",
      "  (fc1): Sequential(\n",
      "    (0): Conv2d(4, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (graph_conv): DyGraphConv2d(\n",
      "    (gconv): EdgeConv2d(\n",
      "      (nn): BasicConv(\n",
      "        (0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), groups=4)\n",
      "        (1): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (dilated_knn_graph): DenseDilatedKnnGraph(\n",
      "      (_dilated): DenseDilated()\n",
      "    )\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Conv2d(8, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (drop_path): Identity()\n",
      ")\n",
      "hi\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "from vig import Grapher\n",
    "\n",
    "num_patches = 225\n",
    "\n",
    "grapher_module = Grapher(\n",
    "    in_channels=4,         # RGB image has 3 channels\n",
    "    kernel_size=3,         # A common choice, could be different based on your architecture\n",
    "    dilation=1,            # Standard dilation\n",
    "    conv='edge',           # Replace 'edge' with the actual type used in your model\n",
    "    act='relu',            # A common activation function\n",
    "    norm=None,             # Depends on whether you want to use normalization\n",
    "    bias=True,             # Typically, biases are used\n",
    "    stochastic=False,      # If stochastic depth is not used\n",
    "    epsilon=0.0,           # Hyperparameter for the edge convolution\n",
    "    r=1,                   # Downsampling rate\n",
    "    n=num_patches,         # Number of nodes\n",
    "    drop_path=0.0,         # Drop path rate for stochastic depth\n",
    "    relative_pos=True,\n",
    "    # groups = 1     # Set to True if the model uses relative positions\n",
    ")\n",
    "\n",
    "grapher_module = grapher_module.to(permuted_images_tensors[0].device)\n",
    "print(grapher_module)\n",
    "\n",
    "graph_output = grapher_module(permuted_images_tensors[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pool = nn.AdaptiveAvgPool2d((14, 14))\n",
    "\n",
    "pooled_output = pool(graph_output)\n",
    "\n",
    "print(pooled_output.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gcn_lib import DenseDilatedKnnGraph\n",
    "\n",
    "dense_dilated_knn_graph = DenseDilatedKnnGraph(k=20, dilation=1, stochastic=False, epsilon=0.0)\n",
    "\n",
    "num_points = pooled_output.shape[2] * pooled_output.shape[3]  # For a 224x224 image, this would be 50176\n",
    "pooled_output_reshaped = pooled_output.reshape(1, 4, num_points, 1)  # Reshape to [1, 4, 50176, 1]\n",
    "\n",
    "# Use the module to find edges\n",
    "edge_index = dense_dilated_knn_graph(pooled_output_reshaped)\n",
    "\n",
    "# edge_index now contains the indices of edges based on dilated KNN\n",
    "edge_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=9\n",
    "edge_index_flat = edge_index.view(2, -1)\n",
    "\n",
    "edge_index_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = edge_index_flat.shape[1] // k  \n",
    "print(N)\n",
    "adjacency_matrix = torch.zeros((N, N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(edge_index_flat.shape[1]):\n",
    "    source_node = edge_index_flat[0, i]\n",
    "    target_node = edge_index_flat[1, i]\n",
    "\n",
    "    adjacency_matrix[source_node, target_node] = 1\n",
    "\n",
    "edge_list = edge_index_flat.t().tolist()  # Convert to a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 14*14\n",
    "feature_dimension = 4\n",
    "graph_features = pooled_output.reshape(1, feature_dimension, num_nodes)\n",
    "\n",
    "graph_features = graph_features.squeeze(0)  # This is now of shape [4, 50176]\n",
    "\n",
    "node_features = {node: [] for node in range(num_nodes)}  # Dictionary to store features for each node\n",
    "\n",
    "for target_node, source_node in edge_list:\n",
    "\n",
    "    node_features[target_node].append(graph_features[:, source_node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "image_array = permuted_images_tensors[0][0][0]  # Placeholder for the actual image\n",
    "\n",
    "grid_size = 16  # Grid size for the 14x14 grid\n",
    "\n",
    "# Example edge cases\n",
    "edge_nine = [\n",
    "[5, 5],\n",
    "[93, 5],\n",
    "[191, 5],\n",
    "[107, 5],\n",
    "[123, 5],\n",
    "[19, 5],\n",
    "[121, 5],\n",
    "[137, 5],\n",
    "[158, 5],\n",
    "[94, 5],\n",
    "[177, 5],\n",
    "[32, 5],\n",
    "[163, 5],\n",
    "[95, 5],\n",
    "[124, 5],\n",
    "[18, 5],\n",
    "[30, 5],\n",
    "[17, 5],\n",
    "[72, 5],\n",
    "[52, 5]]\n",
    "\n",
    "# Display the image as a background\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.imshow(image_array, extent=[0, grid_size-1, grid_size-1, 0])\n",
    "\n",
    "\n",
    "ax.set_xlim([0, grid_size-1])\n",
    "ax.set_ylim([0, grid_size-1])\n",
    "ax.set_aspect('equal')\n",
    "# Inverting y-axis to have (0,0) at top-left\n",
    "ax.set_ylim(ax.get_ylim()[::-1])\n",
    "\n",
    "ax.set_xticks(np.arange(0, grid_size, 1))\n",
    "ax.set_yticks(np.arange(0, grid_size, 1))\n",
    "\n",
    "\n",
    "# Overlay the connections on top of the image\n",
    "for conn in edge_nine:\n",
    "\n",
    "    x1, y1 = ((conn[0]) % 15, (conn[0]) // 15)\n",
    "    x2, y2 = ((conn[1]) % 15, (conn[1]) // 15)\n",
    "\n",
    "    x1_adjust = x1 + 0.5\n",
    "\n",
    "    x2_adjust = x2 + 0.5\n",
    "    \n",
    "    plt.plot([x1_adjust, x2_adjust], [y1 + 0.5, y2 + 0.5], marker='o', markersize=5, linestyle='-', color='red', linewidth=1)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
