{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdversarialLoss(nn.Module):\n",
    "    def __init__(self, discriminator):\n",
    "        super(AdversarialLoss, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def forward(self, real_images, fake_images):\n",
    "        real_logits = self.discriminator(real_images)\n",
    "        fake_logits = self.discriminator(fake_images.detach())\n",
    "\n",
    "        d_loss_real = F.binary_cross_entropy_with_logits(real_logits, torch.ones_like(real_logits))\n",
    "        d_loss_fake = F.binary_cross_entropy_with_logits(fake_logits, torch.zeros_like(fake_logits))\n",
    "        g_loss = F.binary_cross_entropy_with_logits(fake_logits, torch.ones_like(fake_logits))\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        return g_loss, d_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundaryLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BoundaryLoss, self).__init__()\n",
    "\n",
    "    def forward(self, decoded_images):\n",
    "        batch_size, channels, height, width = decoded_images.size()\n",
    "\n",
    "        # Reshape images into n x n pieces\n",
    "        pieces = decoded_images.view(batch_size, channels, n, -1)\n",
    "\n",
    "        # Calculate SSIM for top-bottom relationships\n",
    "        top_bottom_ssim = torch.zeros(batch_size)\n",
    "        for i in range(n):\n",
    "            top_piece = pieces[:, :, i, :]\n",
    "            bottom_piece = pieces[:, :, (i + 1) % n, :]\n",
    "            top_bottom_ssim += F.ssim(top_piece[:, :, -1, :], bottom_piece[:, :, 0, :], data_range=1)\n",
    "\n",
    "        # Calculate SSIM for left-right relationships\n",
    "        left_right_ssim = torch.zeros(batch_size)\n",
    "        for j in range(n):\n",
    "            left_piece = pieces[:, :, :, j]\n",
    "            right_piece = pieces[:, :, :, (j + 1) % n]\n",
    "            left_right_ssim += F.ssim(left_piece[:, :, :, -1], right_piece[:, :, :, 0], data_range=1)\n",
    "\n",
    "        # Compute average SSIM scores\n",
    "        top_bottom_ssim /= n\n",
    "        left_right_ssim /= n\n",
    "\n",
    "        # Boundary loss\n",
    "        loss = (1 - top_bottom_ssim.mean()) + (1 - left_right_ssim.mean())\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Jigsaw Loss class\n",
    "class JigsawLoss(nn.Module):\n",
    "    def __init__(self, reference_labels):\n",
    "        super(JigsawLoss, self).__init__()\n",
    "        self.reference_labels = reference_labels\n",
    "\n",
    "    def forward(self, predicted_distribution):\n",
    "        batch_size, num_categories = predicted_distribution.size()\n",
    "\n",
    "        # Compute focal loss\n",
    "        focal_loss = -torch.sum((1 - predicted_distribution * self.reference_labels) ** 2 * torch.log(predicted_distribution))\n",
    "\n",
    "        # Average over batch size\n",
    "        loss = focal_loss / batch_size\n",
    "        return loss\n",
    "\n",
    "# Helper functions\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def cut_boundaries(img, pix):\n",
    "    top_boundary = img[:pix, :]\n",
    "    bottom_boundary = img[-pix:, :]\n",
    "    left_boundary = img[:, :pix]\n",
    "    right_boundary = img[:, -pix:]\n",
    "    return top_boundary, bottom_boundary, left_boundary, right_boundary\n",
    "\n",
    "def compute_relationships(top_boundaries, bottom_boundaries, left_boundaries, right_boundaries):\n",
    "    n = len(top_boundaries)\n",
    "    top_bottom_relationships = np.zeros((n, n))\n",
    "    left_right_relationships = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                top_bottom_relationships[i, j] = calculate_psnr(top_boundaries[i], bottom_boundaries[j])\n",
    "                left_right_relationships[i, j] = calculate_psnr(left_boundaries[i], right_boundaries[j])\n",
    "    \n",
    "    return top_bottom_relationships, left_right_relationships\n",
    "\n",
    "def greedy_algorithm(top_bottom_relationships, left_right_relationships):\n",
    "    n = len(top_bottom_relationships)\n",
    "    selected_top_bottom = []\n",
    "    selected_left_right = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        max_top_bottom_idx = np.unravel_index(np.argmax(top_bottom_relationships), top_bottom_relationships.shape)\n",
    "        max_left_right_idx = np.unravel_index(np.argmax(left_right_relationships), left_right_relationships.shape)\n",
    "        \n",
    "        selected_top_bottom.append(max_top_bottom_idx)\n",
    "        selected_left_right.append(max_left_right_idx)\n",
    "        \n",
    "        top_bottom_relationships[max_top_bottom_idx] = -np.inf\n",
    "        left_right_relationships[max_left_right_idx] = -np.inf\n",
    "    \n",
    "    return selected_top_bottom, selected_left_right\n",
    "\n",
    "def minimum_spanning_tree(selected_top_bottom, selected_left_right):\n",
    "    # Initialize variables\n",
    "    n = len(selected_top_bottom)\n",
    "    visited = [False] * n\n",
    "    parent = [-1] * n\n",
    "    key = [float('inf')] * n\n",
    "\n",
    "    # Start with the first node\n",
    "    key[0] = 0\n",
    "\n",
    "    # Construct MST\n",
    "    for _ in range(n):\n",
    "        # Find the vertex with the minimum key value\n",
    "        min_key = float('inf')\n",
    "        min_idx = -1\n",
    "        for i in range(n):\n",
    "            if not visited[i] and key[i] < min_key:\n",
    "                min_key = key[i]\n",
    "                min_idx = i\n",
    "\n",
    "        # Mark the selected vertex as visited\n",
    "        visited[min_idx] = True\n",
    "\n",
    "        # Update key and parent for adjacent vertices\n",
    "        for j in range(n):\n",
    "            if not visited[j]:\n",
    "                # Update key if the weight is smaller\n",
    "                if (selected_top_bottom[min_idx][0] == j or selected_left_right[min_idx][0] == j) and selected_top_bottom[min_idx][1] > selected_top_bottom[j][1]:\n",
    "                    key[j] = selected_top_bottom[min_idx][1]\n",
    "                    parent[j] = min_idx\n",
    "                if (selected_top_bottom[min_idx][1] == j or selected_left_right[min_idx][1] == j) and selected_left_right[min_idx][0] > selected_left_right[j][0]:\n",
    "                    key[j] = selected_left_right[min_idx][0]\n",
    "                    parent[j] = min_idx\n",
    "\n",
    "    # Construct the reference permutation\n",
    "    reference_permutation = []\n",
    "    for i in range(1, n):\n",
    "        reference_permutation.append((parent[i], i))\n",
    "\n",
    "    return reference_permutation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
