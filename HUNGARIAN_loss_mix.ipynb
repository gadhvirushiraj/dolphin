{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a6GBYFP_yyFt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from torchvision.transforms import Normalize\n",
        "\n",
        "#soham:\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from scipy.optimize import linear_sum_assignment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LSVwQMFlyyFw"
      },
      "outputs": [],
      "source": [
        "def divide_image(image):\n",
        "    parts = []\n",
        "    height, width, _ = image.shape\n",
        "    part_height = height // 3\n",
        "    part_width = width // 3\n",
        "\n",
        "    for i in range(3):\n",
        "        for j in range(3):\n",
        "            part = image[i*part_height:(i+1)*part_height, j*part_width:(j+1)*part_width]\n",
        "            parts.append(part)\n",
        "\n",
        "    return parts\n",
        "\n",
        "def generate_combinations(parts, num_combinations):\n",
        "    combinations = []\n",
        "    original_positions = []\n",
        "    indices = list(range(len(parts)))\n",
        "\n",
        "    for _ in range(num_combinations):\n",
        "        random.shuffle(indices)\n",
        "        combination = [parts[i] for i in indices]\n",
        "        combinations.append(combination)\n",
        "        original_positions.append(indices.copy())\n",
        "\n",
        "    return combinations, original_positions\n",
        "def stitch_shuffled_image(parts):\n",
        "    num_parts = len(parts)\n",
        "    part_size = parts[0].shape[0]  # Assuming all parts are square\n",
        "\n",
        "    stitched_image_size = int(np.sqrt(num_parts) * part_size)\n",
        "    stitched_image = np.zeros((stitched_image_size, stitched_image_size, parts[0].shape[2]), dtype=np.uint8)\n",
        "\n",
        "    for i in range(stitched_image.shape[0] // part_size):\n",
        "        for j in range(stitched_image.shape[1] // part_size):\n",
        "            part_index = i * int(stitched_image.shape[0] / part_size) + j\n",
        "            stitched_image[i*part_size:(i+1)*part_size, j*part_size:(j+1)*part_size] = parts[part_index]\n",
        "\n",
        "    return stitched_image\n",
        "# checking if the target sequence is correct\n",
        "def reconstructed_image(img, non_converted_target_data, test=False):\n",
        "\n",
        "    sequenced = [0] * 9\n",
        "    for i in range(0,27,3):\n",
        "\n",
        "        # stack the 3 channels to get the original image\n",
        "        blue_channel = img[:,:,i]\n",
        "        green_channel = img[:,:,i+1]\n",
        "        red_channel = img[:,:,i+2]\n",
        "\n",
        "        # stack the 3 channels to get the original image\n",
        "        tile = np.stack((blue_channel, green_channel, red_channel), axis=2)\n",
        "\n",
        "        if test:\n",
        "            sequenced[i // 3] = tile\n",
        "        else:\n",
        "            sequenced[non_converted_target_data[i // 3]] = tile\n",
        "\n",
        "    stiched_img = stitch_shuffled_image(sequenced)\n",
        "    return stiched_img\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "aLPUDhcnyyFw"
      },
      "outputs": [],
      "source": [
        "class JigsawDataset(Dataset):\n",
        "    def __init__(self, input_data, target_data, transform=None):\n",
        "        self.input_data = input_data\n",
        "        self.target_data = target_data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.input_data[idx]\n",
        "        target = self.target_data[idx]\n",
        "\n",
        "        # Convert NumPy arrays to float tensors\n",
        "        image = torch.from_numpy(image).float()\n",
        "        target = torch.from_numpy(target)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, target\n",
        "\n",
        "class JigsawModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(JigsawModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(27, 64, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 10 * 10, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 1024)\n",
        "        self.fc3 = nn.Linear(1024, 512)\n",
        "        self.fc4 = nn.Linear(512, 81)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.reshape(-1, 128 * 10 * 10)  # Replace view with reshape\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f-mR4JPyyyFx"
      },
      "outputs": [],
      "source": [
        "# # Define the JigsawModel class with batch normalization layers\n",
        "# class JigsawModel(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(JigsawModel, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(27, 64, 3, padding=1)\n",
        "#         self.bn1 = nn.BatchNorm2d(64)  # Batch normalization layer\n",
        "#         self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "#         self.bn2 = nn.BatchNorm2d(128)  # Batch normalization layer\n",
        "#         self.pool = nn.MaxPool2d(2, 2)\n",
        "#         self.fc1 = nn.Linear(128 * 10 * 10, 4096)\n",
        "#         self.fc2 = nn.Linear(4096, 1024)\n",
        "#         self.fc3 = nn.Linear(1024, 512)\n",
        "#         self.fc4 = nn.Linear(512, 81)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "#         x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "#         x = x.view(-1, 128 * 10 * 10)\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = F.relu(self.fc3(x))\n",
        "#         x = self.fc4(x)\n",
        "\n",
        "#         return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A9Lw5GzWyyFx"
      },
      "outputs": [],
      "source": [
        "# class BoundaryLoss(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(BoundaryLoss, self).__init__()\n",
        "\n",
        "#     def forward(self, outputs, labels):\n",
        "#         batch_size = outputs.size(0)\n",
        "#         top_bottom_ssim = torch.zeros(batch_size)\n",
        "#         left_right_ssim = torch.zeros(batch_size)\n",
        "\n",
        "#         for i in range(batch_size):\n",
        "#             # Reshape the outputs and labels to match SSIM function requirements\n",
        "#             output_img = outputs[i].view(9, 9).unsqueeze(0).unsqueeze(0)\n",
        "#             label_img = labels[i].view(9, 9).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "#             # Compute SSIM\n",
        "#             top_bottom_ssim[i] = 1 - torch.mean(torch.abs(output_img[0, :, 0, :] - label_img[0, :, -1, :]))\n",
        "#             left_right_ssim[i] = 1 - torch.mean(torch.abs(output_img[0, 0, :, :] - label_img[0, -1, :, :]))\n",
        "\n",
        "#         avg_tb_ssim = torch.mean(top_bottom_ssim)\n",
        "#         avg_lr_ssim = torch.mean(left_right_ssim)\n",
        "\n",
        "#         loss = avg_tb_ssim + avg_lr_ssim\n",
        "\n",
        "#         return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def hungarian_loss(outputs, labels):\n",
        "    batch_size = outputs.size(0)\n",
        "    n = outputs.size(1)\n",
        "\n",
        "    # Reshape outputs and labels to 2D matrices\n",
        "    outputs = outputs.view(batch_size, -1)\n",
        "    labels = labels.view(batch_size, -1)\n",
        "\n",
        "    # Calculate pairwise distance\n",
        "    dist = torch.cdist(outputs, labels, p=2)\n",
        "\n",
        "    # Solve the assignment problem using the Hungarian algorithm\n",
        "    cost_matrix = dist.cpu().detach().numpy()\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_matrix)\n",
        "\n",
        "    # Compute the Hungarian loss\n",
        "    loss = torch.tensor(cost_matrix[row_ind, col_ind].sum() / batch_size)\n",
        "\n",
        "    return loss.to(outputs.device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yPi86-obEdg2",
        "outputId": "71d9f13c-6899-4147-9f30-dc02f218088e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qBmPCsgkyyFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e3d232-959c-46cd-fc61-6ba414d3cb26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "images = np.load('/content/drive/MyDrive/tranformed_cavallo.npy')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GfaPcUvHyyFx"
      },
      "outputs": [],
      "source": [
        "input_data = []\n",
        "target_data = []\n",
        "non_converted_target_data = []\n",
        "\n",
        "for image in images:\n",
        "    parts = divide_image(image)\n",
        "    combinations, original_positions = generate_combinations(parts, 10)\n",
        "\n",
        "    for idx, combination in enumerate(combinations):\n",
        "\n",
        "        # shape of combination is (9, 40, 40, 3)\n",
        "        combination = np.array(combination).transpose(0, 3, 1, 2)\n",
        "        combination = np.concatenate(combination, axis=0).transpose(1, 2, 0)\n",
        "        input_data.append(combination)\n",
        "\n",
        "        dummy_target = np.zeros((9, 9), dtype=np.uint8)\n",
        "        for i in range(9):\n",
        "            dummy_target[i, original_positions[idx][i]] = 1\n",
        "\n",
        "        target_data.append(dummy_target.flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "3mXk4N14yyFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35066417-03b1-4191-8877-1c3158d830f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JigsawModel(\n",
            "  (conv1): Conv2d(27, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=12800, out_features=4096, bias=True)\n",
            "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc4): Linear(in_features=512, out_features=81, bias=True)\n",
            ")\n",
            "Number of trainable parameters: 57284049\n",
            "JigsawModel(\n",
            "  (conv1): Conv2d(27, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=12800, out_features=4096, bias=True)\n",
            "  (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (fc4): Linear(in_features=512, out_features=81, bias=True)\n",
            ")\n",
            "Number of trainable parameters: 57284049\n"
          ]
        }
      ],
      "source": [
        "# model = JigsawModel()\n",
        "# boundary_loss_fn = BoundaryLoss()\n",
        "# adversarial_loss_fn = nn.BCELoss()\n",
        "# weight_adversarial = 0.5  # Adjust as needed\n",
        "# weight_boundary = 0.5\n",
        "# num_epochs = 20\n",
        "# batch_size = 64\n",
        "# soham:\n",
        "\n",
        "model = JigsawModel()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)  # Move model to GPU if available\n",
        "\n",
        "print(model)\n",
        "print(\"Number of trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "criterion = hungarian_loss\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "num_epochs = 10\n",
        "batch_size = 64\n",
        "print(model)\n",
        "print(\"Number of trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "# scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uXGoLSieyyFy"
      },
      "outputs": [],
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_data, target_data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Apply normalization transform to your dataset\n",
        "train_dataset = JigsawDataset(X_train, y_train)\n",
        "test_dataset = JigsawDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "R2Ci7KaiyyFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb59983-7931-4549-8f1a-e7e59ad6492e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch:   100, Loss: 10.301\n",
            "Epoch: 1, Batch:   200, Loss: 10.367\n",
            "Epoch: 1, Batch:   300, Loss: 10.275\n",
            "Epoch [1/10], Loss: 278.5815076828003, Accuracy: 0.0\n",
            "Epoch: 2, Batch:   100, Loss: 10.285\n",
            "Epoch: 2, Batch:   200, Loss: 10.309\n",
            "Epoch: 2, Batch:   300, Loss: 10.332\n",
            "Epoch [2/10], Loss: 279.86637592315674, Accuracy: 0.0\n",
            "Epoch: 3, Batch:   100, Loss: 10.305\n",
            "Epoch: 3, Batch:   200, Loss: 10.318\n",
            "Epoch: 3, Batch:   300, Loss: 10.336\n",
            "Epoch [3/10], Loss: 276.4600124359131, Accuracy: 0.0\n",
            "Epoch: 4, Batch:   100, Loss: 10.319\n",
            "Epoch: 4, Batch:   200, Loss: 10.299\n",
            "Epoch: 4, Batch:   300, Loss: 10.332\n",
            "Epoch [4/10], Loss: 277.9919328689575, Accuracy: 0.0\n",
            "Epoch: 5, Batch:   100, Loss: 10.275\n",
            "Epoch: 5, Batch:   200, Loss: 10.334\n",
            "Epoch: 5, Batch:   300, Loss: 10.339\n",
            "Epoch [5/10], Loss: 277.6602029800415, Accuracy: 0.0\n",
            "Epoch: 6, Batch:   100, Loss: 10.332\n",
            "Epoch: 6, Batch:   200, Loss: 10.323\n",
            "Epoch: 6, Batch:   300, Loss: 10.287\n",
            "Epoch [6/10], Loss: 278.2001495361328, Accuracy: 0.0\n",
            "Epoch: 7, Batch:   100, Loss: 10.324\n",
            "Epoch: 7, Batch:   200, Loss: 10.310\n",
            "Epoch: 7, Batch:   300, Loss: 10.309\n",
            "Epoch [7/10], Loss: 278.070463180542, Accuracy: 0.0\n",
            "Epoch: 8, Batch:   100, Loss: 10.317\n",
            "Epoch: 8, Batch:   200, Loss: 10.320\n",
            "Epoch: 8, Batch:   300, Loss: 10.302\n",
            "Epoch [8/10], Loss: 278.327036857605, Accuracy: 0.0\n",
            "Epoch: 9, Batch:   100, Loss: 10.308\n",
            "Epoch: 9, Batch:   200, Loss: 10.319\n",
            "Epoch: 9, Batch:   300, Loss: 10.313\n",
            "Epoch [9/10], Loss: 278.591513633728, Accuracy: 0.0\n",
            "Epoch: 10, Batch:   100, Loss: 10.287\n",
            "Epoch: 10, Batch:   200, Loss: 10.327\n",
            "Epoch: 10, Batch:   300, Loss: 10.316\n",
            "Epoch [10/10], Loss: 279.61852169036865, Accuracy: 0.0\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Define the weights for the Hungarian and Cross Entropy losses\n",
        "weight_hungarian = 0.5\n",
        "weight_ce = 0.5\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.permute(0, 3, 1, 2).float().to(device)  # Move inputs to the same device as the model\n",
        "        labels = labels.to(device)  # Move labels to the same device as the model\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # Calculate Hungarian loss\n",
        "        hungarian_loss = your_hungarian_loss_function(outputs, labels)\n",
        "\n",
        "        # Calculate Cross Entropy loss\n",
        "        ce_loss = criterion(outputs, labels.float())\n",
        "\n",
        "        # Combine the losses with weights\n",
        "        total_loss = weight_hungarian * hungarian_loss + weight_ce * ce_loss\n",
        "\n",
        "        # Ensure that total loss requires gradients\n",
        "        total_loss.requires_grad = True\n",
        "\n",
        "        total_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += total_loss.item()\n",
        "        if i % 100 == 99:\n",
        "            print('Epoch: %d, Batch: %5d, Loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, predicted_indices = torch.max(outputs, 1)  # Get the index with the highest probability\n",
        "        predicted_labels = torch.zeros_like(labels)\n",
        "        for i, idx in enumerate(predicted_indices):\n",
        "            predicted_labels[i, idx] = 1  # Convert index to one-hot encoding\n",
        "\n",
        "        correct = (predicted_labels == labels).all(dim=1).sum().item()\n",
        "        total_correct += correct\n",
        "        total_samples += labels.size(0)\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss}, Accuracy: {accuracy}')\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = random.randint(0, len(X_test))\n",
        "image = X_test[idx]\n",
        "target = y_test[idx]\n",
        "inputs = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).float()\n",
        "outputs = model(inputs)\n",
        "outputs = outputs.reshape(9, 9)\n",
        "print(outputs)\n",
        "converted_target = np.argmax(target.reshape(9, 9), axis=1)\n",
        "print(converted_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoqvw9lXN-kw",
        "outputId": "417dae5a-53aa-4a58-a4c6-9ad568e34c0a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.0691,  1.9661,  1.9562,  0.7019,  1.6677,  0.9236,  0.9957,  0.6199,\n",
            "          1.1292],\n",
            "        [ 0.3475,  0.4670, -0.6204, -0.9456,  0.4840, -0.1379, -1.3853, -3.0874,\n",
            "          0.9183],\n",
            "        [ 0.3471, -0.5949,  0.0750,  2.9881,  0.9705,  0.0495, -1.4054,  2.6288,\n",
            "         -0.5224],\n",
            "        [-1.5066, -1.3019, -0.4854,  0.9044, -0.4017,  0.1754,  1.0671,  1.2370,\n",
            "          0.1224],\n",
            "        [-0.0730,  0.7724,  2.2766, -1.2377,  1.5424, -1.4046, -1.5353,  0.7747,\n",
            "          0.6702],\n",
            "        [ 0.4426,  1.0194,  2.1990, -0.7269, -0.2335, -1.4189,  0.5581, -1.2809,\n",
            "          1.2122],\n",
            "        [ 0.5904,  1.4663,  0.1507,  1.9854,  0.6001,  0.4612,  1.2083,  1.1583,\n",
            "          0.8806],\n",
            "        [ 1.2785, -0.0951, -1.5371, -0.0650,  1.8375, -0.0039, -1.5387, -0.9211,\n",
            "         -0.9900],\n",
            "        [-0.0524,  1.1667, -0.7166,  2.7564,  0.2570, -0.7949,  0.9241,  1.8795,\n",
            "          0.3706]], grad_fn=<ViewBackward0>)\n",
            "[2 0 8 1 6 4 5 7 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'saved_models/soham_loss.pth')"
      ],
      "metadata": {
        "id": "AQ7gsTNKNzCg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OsGWrT0byyFz"
      },
      "outputs": [],
      "source": [
        "def recur(sequence, outputs):\n",
        "    sequence = np.array(sequence)\n",
        "    for i in range(len(sequence)):\n",
        "        while np.sum(sequence == sequence[i]) > 1:  # If the current element is a duplicate\n",
        "            # Find the index in outputs for the current sequence element that is not yet in the updated sequence\n",
        "            scores = outputs[i]\n",
        "            sorted_indices = np.argsort(scores)[::-1]  # Indices of scores sorted in descending order\n",
        "            for idx in sorted_indices:\n",
        "                if idx not in sequence:\n",
        "                    sequence[i] = idx\n",
        "                    break\n",
        "\n",
        "    return sequence.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "txt3kkFpyyFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15625811-9a3c-4046-a6cd-14a989d5545c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on test images: 0 %\n",
            "Per tile accuracy on test images: 10 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "per_tile_accuracy = 0\n",
        "################\n",
        "model.to(\"cpu\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.permute(0, 3, 1, 2).float()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        # reshape the output to 9x9 matrix\n",
        "        outputs = outputs.reshape(-1, 9, 9)\n",
        "        predicted = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        # now doing the same for the target\n",
        "        labels = labels.reshape(-1, 9, 9)\n",
        "        target = torch.argmax(labels, dim=1)\n",
        "\n",
        "        # check if the predicted sequence is correct\n",
        "        for i in range(len(predicted)):\n",
        "            updated_predicted = recur(predicted[i], outputs[i, : , :].numpy())\n",
        "\n",
        "            if torch.equal(torch.tensor(updated_predicted), target[i]):\n",
        "                correct += 1\n",
        "            total += 1\n",
        "\n",
        "            per_tile_accuracy += (np.array(updated_predicted) == target[i].numpy()).sum() / 9\n",
        "\n",
        "print('Accuracy on test images: %d %%' % (100 * correct / total))\n",
        "print('Per tile accuracy on test images: %d %%' % (100 * per_tile_accuracy / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TOW0jOs0yyFz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('saved_models', exist_ok=True)\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'saved_models/hung_loss.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMVgoQe1yyFz"
      },
      "outputs": [],
      "source": [
        "# idx = random.randint(0, len(X_test))\n",
        "# image = X_test[idx]\n",
        "# target = y_test[idx]\n",
        "# inputs = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).float()\n",
        "# outputs = model(inputs)\n",
        "# outputs = outputs.reshape(9, 9)\n",
        "# print(outputs)\n",
        "# converted_target = np.argmax(target.reshape(9, 9), axis=1)\n",
        "# print(converted_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDah1fDEyyFz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}